{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Evaluation\n",
    "In this notebook, we evaluate the CVCL model on our konkle object dataset that has been augmented with more colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Color Annotations\n",
    "First, we read in the annotations for different colors. Each color corresponds to a separate csv file that contains annotations from multiple annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 447 images that are annotated with at least one color.\n",
      "blue: 98 images.\n",
      "red: 48 images.\n",
      "yellow: 63 images.\n",
      "green: 142 images.\n",
      "brown: 34 images.\n",
      "orange: 21 images.\n",
      "pink: 53 images.\n",
      "purple: 70 images.\n",
      "Image packingtape_rot_s_10.jpg has been annotated with: blue and purple\n",
      "Image extension_cord_s_8.jpg has been annotated with: blue and green\n",
      "Image holy_vase_rot_s_4.jpg has been annotated with: blue and purple\n",
      "Image watch_rot_s_3.jpg has been annotated with: blue and green\n",
      "Image pail_rot_s_10.jpg has been annotated with: blue and purple\n",
      "Image takeout_container_rot_s_5.jpg has been annotated with: blue and green\n",
      "Image packingtape_rot_s_9.jpg has been annotated with: blue and purple\n",
      "Image takeout_container_rot_s_6.jpg has been annotated with: blue and green\n",
      "Image notebook_rot_s_6.jpg has been annotated with: red and brown\n",
      "Image phone_antique_rot_s_10.jpg has been annotated with: red and pink\n",
      "Image fuel_tank_rot_s_5.jpg has been annotated with: red and pink\n",
      "Image holy_vase_rot_s_7.jpg has been annotated with: red and pink\n",
      "Image sugar_bowl_rot_s_5.jpg has been annotated with: red and pink\n",
      "Image notecards_rot_s_7.jpg has been annotated with: red and pink\n",
      "Image notecards_rot_s_8.jpg has been annotated with: red and pink\n",
      "Image sugar_bowl_rot_s_6.jpg has been annotated with: red and pink\n",
      "Image accordion_rot_s_9.jpg has been annotated with: red and brown\n",
      "Image chapstick_rot_s_9.jpg has been annotated with: red and pink\n",
      "Image kettle_rot_s_3.jpg has been annotated with: red and pink\n",
      "Image gloves_rot_s_10.jpg has been annotated with: red and brown\n",
      "Image notebook_rot_s_5.jpg has been annotated with: red and brown\n",
      "Image sponge_rot_s_6.jpg has been annotated with: red and pink\n",
      "Image kettle_rot_s_4.jpg has been annotated with: red and pink\n",
      "Image holy_vase_rot_s_8.jpg has been annotated with: red and pink\n",
      "Image chair_rot_s_4.jpg has been annotated with: red and orange\n",
      "Image extension_cord_rot_s_7.jpg has been annotated with: red and brown\n",
      "Image sponge_rot_s_5.jpg has been annotated with: red and pink\n",
      "Image fuel_tank_rot_s_6.jpg has been annotated with: red and pink\n",
      "Image extension_cord_s_6.jpg has been annotated with: red and purple\n",
      "Image gift_box_rot_s_1.jpg has been annotated with: red and brown\n",
      "Image tennis_racket_rot_s_3.jpg has been annotated with: red and pink\n",
      "Image valve_rot_s_8.jpg has been annotated with: red and pink\n",
      "Image accordion_rot_s_8.jpg has been annotated with: red and brown\n",
      "Image chapstick_rot_s_10.jpg has been annotated with: red and pink\n",
      "Image flask_rot_s_5.jpg has been annotated with: red and brown\n",
      "Image phone_antique_rot_s_9.jpg has been annotated with: red and pink\n",
      "Image tennis_racket_rot_s_4.jpg has been annotated with: red and pink\n",
      "Image container_open_rot_s_2.jpg has been annotated with: red and pink\n",
      "Image gift_box_rot_s_2.jpg has been annotated with: red and brown\n",
      "Image valve_rot_s_7.jpg has been annotated with: red and pink\n",
      "Image cocktail_umbrella_rot_s_7.jpg has been annotated with: yellow and orange\n",
      "Image takeout_container_rot_s_7.jpg has been annotated with: yellow and orange\n",
      "Image hand_puppet_rot_s_4.jpg has been annotated with: yellow and green\n",
      "Image sugar_bowl_rot_s_3.jpg has been annotated with: yellow and green\n",
      "Image theater_seats_rot_s_9.jpg has been annotated with: yellow and green\n",
      "Image accordion_rot_s_10.jpg has been annotated with: yellow and green\n",
      "Image watch_rot_s_5.jpg has been annotated with: yellow and green\n",
      "Image hand_puppet_rot_s_3.jpg has been annotated with: yellow and green\n",
      "Image fuel_tank_rot_s_4.jpg has been annotated with: yellow and green\n",
      "Image sugar_bowl_rot_s_4.jpg has been annotated with: yellow and green\n",
      "Image razor_rot_s_7.jpg has been annotated with: yellow and green\n",
      "Image notecards_rot_s_10.jpg has been annotated with: yellow and brown\n",
      "Image controlbox_rot_s_2.jpg has been annotated with: yellow and green\n",
      "Image packingtape_rot_s_4.jpg has been annotated with: yellow and green\n",
      "Image razor_rot_s_8.jpg has been annotated with: yellow and green\n",
      "Image nailpolish_rot_s_8.jpg has been annotated with: yellow and brown\n",
      "Image packingtape_rot_s_3.jpg has been annotated with: yellow and green\n",
      "Image pail_rot_s_1.jpg has been annotated with: yellow and green\n",
      "Image jacket_rot_s_9.jpg has been annotated with: yellow and green\n",
      "Image notecards_rot_s_9.jpg has been annotated with: yellow and brown\n",
      "Image lotion_rot_s_1.jpg has been annotated with: yellow and brown\n",
      "Image usb_key_rot_s_6.jpg has been annotated with: yellow and green\n",
      "Image pail_rot_s_2.jpg has been annotated with: yellow and green\n",
      "Image umbrella_rot_s_3.jpg has been annotated with: yellow and orange\n",
      "Image umbrella_rot_s_2.jpg has been annotated with: yellow and green\n",
      "Image theater_seats_rot_s_10.jpg has been annotated with: yellow and green\n",
      "Image lotion_rot_s_2.jpg has been annotated with: yellow and brown\n",
      "Image measuring_spoons_rot_s_2.jpg has been annotated with: yellow and brown\n",
      "Image measuring_spoons_rot_s_1.jpg has been annotated with: yellow and brown\n",
      "Image fuel_tank_rot_s_3.jpg has been annotated with: yellow and green\n",
      "Image controlbox_rot_s_1.jpg has been annotated with: yellow and green\n",
      "Image usb_key_rot_s_5.jpg has been annotated with: yellow and green\n",
      "Image cocktail_umbrella_rot_s_8.jpg has been annotated with: yellow and orange\n",
      "Image extension_cord_rot_s_9.jpg has been annotated with: yellow and green\n",
      "Image umbrella_rot_s_4.jpg has been annotated with: yellow and orange\n",
      "Image takeout_container_rot_s_8.jpg has been annotated with: yellow and orange\n",
      "Image umbrella_rot_s_1.jpg has been annotated with: yellow and green\n",
      "Image jacket_rot_s_10.jpg has been annotated with: yellow and green\n",
      "Image controlbox_rot_s_3.jpg has been annotated with: brown and orange\n",
      "Image tennis_racket_rot_s_1.jpg has been annotated with: brown and orange\n",
      "Image controlbox_rot_s_4.jpg has been annotated with: brown and orange\n",
      "Image tennis_racket_rot_s_2.jpg has been annotated with: brown and orange\n"
     ]
    }
   ],
   "source": [
    "import csv, os\n",
    "from collections import defaultdict\n",
    "\n",
    "COLORS_TEST = [\n",
    "    \"blue\",\n",
    "    \"red\",\n",
    "    \"yellow\",\n",
    "    \"green\",\n",
    "    \"brown\",\n",
    "    \"orange\",\n",
    "    \"pink\",\n",
    "    \"purple\"\n",
    "]\n",
    "\n",
    "color_to_images_dict = {}\n",
    "all_images_with_annotations = []\n",
    "image_to_colors_dict = defaultdict(list)\n",
    "\n",
    "for c in COLORS_TEST:\n",
    "    with open(f\"annotations/Color Annotation - {c}.csv\") as f:\n",
    "        lines = csv.DictReader(f)\n",
    "        lines = list(set([(l[\"annotator\"], l[\"image_id\"]) for l in lines])) # set to remove duplicates within one csv\n",
    "        for i,l in enumerate(lines):\n",
    "            if not l[1].endswith(\".jpg\"): # manually correct suffix for image id if annotators forget them\n",
    "                lines[i] = (l[0], l[1]+\".jpg\")\n",
    "        lines = [l for l in lines if os.path.isfile(\"konkle_objects_colored/\"+l[1])] # remove \n",
    "        image_ids = [l[1] for l in lines]\n",
    "        all_images_with_annotations += image_ids\n",
    "        color_to_images_dict[c] = image_ids\n",
    "\n",
    "        # populate image to colors dict\n",
    "        for img in image_ids:\n",
    "            if c not in image_to_colors_dict[img]:\n",
    "                image_to_colors_dict[img].append(c)\n",
    "\n",
    "all_images_with_annotations = list(set(all_images_with_annotations)) # remove duplicates\n",
    "print(f\"There are {len(all_images_with_annotations)} images that are annotated with at least one color.\")\n",
    "\n",
    "for key in color_to_images_dict:\n",
    "    print(f\"{key}: {len(set(color_to_images_dict[key]))} images.\")\n",
    "\n",
    "multiply_annotated_images = []\n",
    "# print the file names of images that are marked with more than one color\n",
    "for key in image_to_colors_dict:\n",
    "    if len(image_to_colors_dict[key]) > 1:\n",
    "        multiply_annotated_images.append(key)\n",
    "        print(f\"Image {key} has been annotated with: {' and '.join(image_to_colors_dict[key])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Object Categories\n",
    "We can find the mapping between object kind to a list of objects of that kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 in tool_box_rot0.\n",
      "There are 5 in valve_rot0.\n",
      "There are 5 in extension_cord_rot1.\n",
      "There are 5 in container_open_rot0.\n",
      "There are 5 in truck_rot1.\n",
      "There are 5 in handbag_rot0.\n",
      "There are 5 in takeout_container_rot1.\n",
      "There are 5 in cardboard_rot0.\n",
      "There are 5 in theater_seats_rot1.\n",
      "There are 5 in gloves_rot0.\n",
      "There are 5 in sponge_rot0.\n",
      "There are 5 in pail_rot1.\n",
      "There are 5 in notebook_rot0.\n",
      "There are 5 in razor_rot1.\n",
      "There are 5 in notebook_rot1.\n",
      "There are 5 in pail_rot0.\n",
      "There are 5 in sponge_rot1.\n",
      "There are 5 in gloves_rot1.\n",
      "There are 5 in theater_seats_rot0.\n",
      "There are 5 in fuel_tank_rot1.\n",
      "There are 5 in cardboard_rot1.\n",
      "There are 5 in takeout_container_rot0.\n",
      "There are 5 in handbag_rot1.\n",
      "There are 5 in container_open_rot1.\n",
      "There are 5 in truck_rot0.\n",
      "There are 5 in valve_rot1.\n",
      "There are 5 in tape_dispenser_rot1.\n",
      "There are 5 in sugar_bowl_rot0.\n",
      "There are 5 in controlbox_rot0.\n",
      "There are 5 in gift_box_rot1.\n",
      "There are 5 in notecards_rot1.\n",
      "There are 5 in notecards_rot0.\n",
      "There are 5 in razor_rot0.\n",
      "There are 5 in hand_puppet_rot0.\n",
      "There are 5 in extension_cord0.\n",
      "There are 5 in gift_box_rot0.\n",
      "There are 5 in controlbox_rot1.\n",
      "There are 5 in fuel_tank_rot0.\n",
      "There are 5 in lotion_rot0.\n",
      "There are 5 in tape_dispenser_rot0.\n",
      "There are 5 in usb_key_rot1.\n",
      "There are 5 in chair_rot0.\n",
      "There are 5 in watch_rot0.\n",
      "There are 5 in kettle_rot0.\n",
      "There are 5 in kettle_rot1.\n",
      "There are 5 in sugar_bowl_rot1.\n",
      "There are 5 in watch_rot1.\n",
      "There are 5 in usb_key_rot0.\n",
      "There are 5 in nailpolish_rot0.\n",
      "There are 5 in towel_rot1.\n",
      "There are 5 in hand_puppet_rot1.\n",
      "There are 5 in accordion_rot0.\n",
      "There are 5 in flask_rot1.\n",
      "There are 5 in scanner_rot0.\n",
      "There are 5 in jacket_rot0.\n",
      "There are 5 in scanner_rot1.\n",
      "There are 5 in flask_rot0.\n",
      "There are 5 in accordion_rot1.\n",
      "There are 5 in umbrella_rot0.\n",
      "There are 5 in towel_rot0.\n",
      "There are 5 in pitcher_rot1.\n",
      "There are 5 in nailpolish_rot1.\n",
      "There are 5 in tool_box_rot1.\n",
      "There are 5 in tennis_racket_rot1.\n",
      "There are 5 in measuring_spoons_rot0.\n",
      "There are 5 in packingtape_rot1.\n",
      "There are 5 in chapstick_rot0.\n",
      "There are 5 in briefcase_rot0.\n",
      "There are 5 in jug_rot0.\n",
      "There are 5 in chair_recliner_rot1.\n",
      "There are 5 in lotion_rot1.\n",
      "There are 5 in cocktail_umbrella_rot1.\n",
      "There are 5 in cocktail_umbrella_rot0.\n",
      "There are 5 in phone_antique_rot1.\n",
      "There are 5 in jug_rot1.\n",
      "There are 5 in briefcase_rot1.\n",
      "There are 5 in chapstick_rot1.\n",
      "There are 5 in measuring_spoons_rot1.\n",
      "There are 5 in pitcher_rot0.\n",
      "There are 5 in tennis_racket_rot0.\n",
      "There are 5 in fakeapple_rot0.\n",
      "There are 5 in packingtape_rot0.\n",
      "There are 5 in chair_recliner_rot0.\n",
      "There are 5 in phone_antique_rot0.\n",
      "There are 5 in fakeapple_rot1.\n",
      "There are 5 in box_hat_rot0.\n",
      "There are 5 in box_hat_rot1.\n",
      "There are 5 in holy_vase_rot0.\n",
      "There are 5 in jacket_rot1.\n",
      "There are 5 in clamp_rot0.\n",
      "There are 5 in clamp_rot1.\n",
      "There are 5 in umbrella_rot1.\n",
      "There are 5 in holy_vase_rot1.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = 'konkle_objects_colored' \n",
    "id_to_object = defaultdict(list)\n",
    "object_to_id = {}\n",
    "for fn in os.listdir(folder_path):\n",
    "    if fn.lower().endswith(\".jpg\"):\n",
    "        assert \"_s_\" in fn\n",
    "        object_name = fn.split(\"_s_\")[0]\n",
    "        object_kind = int(fn.split(\"_s_\")[1].split(\".\")[0]) % 2 # for images with the same prefix, even \n",
    "        object_id = object_name + str(object_kind)\n",
    "        \n",
    "        id_to_object[object_id].append(fn)\n",
    "\n",
    "        object_to_id[fn] = object_id\n",
    "    \n",
    "for object_id in id_to_object:\n",
    "    print(f\"There are {len(id_to_object[object_id])} in {object_id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the id_to_object dictionary, we remove image files that are not annotated with any color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 in tool_box_rot0.\n",
      "There are 4 in valve_rot0.\n",
      "There are 5 in extension_cord_rot1.\n",
      "There are 5 in container_open_rot0.\n",
      "There are 4 in truck_rot1.\n",
      "There are 4 in handbag_rot0.\n",
      "There are 5 in takeout_container_rot1.\n",
      "There are 5 in cardboard_rot0.\n",
      "There are 5 in theater_seats_rot1.\n",
      "There are 5 in gloves_rot0.\n",
      "There are 5 in sponge_rot0.\n",
      "There are 5 in pail_rot1.\n",
      "There are 5 in notebook_rot0.\n",
      "There are 5 in razor_rot1.\n",
      "There are 5 in notebook_rot1.\n",
      "There are 5 in pail_rot0.\n",
      "There are 5 in sponge_rot1.\n",
      "There are 5 in gloves_rot1.\n",
      "There are 5 in theater_seats_rot0.\n",
      "There are 5 in fuel_tank_rot1.\n",
      "There are 5 in cardboard_rot1.\n",
      "There are 5 in takeout_container_rot0.\n",
      "There are 5 in handbag_rot1.\n",
      "There are 5 in container_open_rot1.\n",
      "There are 4 in truck_rot0.\n",
      "There are 4 in valve_rot1.\n",
      "There are 5 in tape_dispenser_rot1.\n",
      "There are 5 in sugar_bowl_rot0.\n",
      "There are 5 in controlbox_rot0.\n",
      "There are 5 in gift_box_rot1.\n",
      "There are 5 in notecards_rot1.\n",
      "There are 5 in notecards_rot0.\n",
      "There are 5 in razor_rot0.\n",
      "There are 5 in hand_puppet_rot0.\n",
      "There are 5 in extension_cord0.\n",
      "There are 5 in gift_box_rot0.\n",
      "There are 5 in controlbox_rot1.\n",
      "There are 5 in fuel_tank_rot0.\n",
      "There are 5 in lotion_rot0.\n",
      "There are 5 in tape_dispenser_rot0.\n",
      "There are 4 in usb_key_rot1.\n",
      "There are 5 in chair_rot0.\n",
      "There are 4 in watch_rot0.\n",
      "There are 5 in kettle_rot0.\n",
      "There are 5 in kettle_rot1.\n",
      "There are 5 in sugar_bowl_rot1.\n",
      "There are 4 in watch_rot1.\n",
      "There are 4 in usb_key_rot0.\n",
      "There are 5 in nailpolish_rot0.\n",
      "There are 5 in towel_rot1.\n",
      "There are 5 in hand_puppet_rot1.\n",
      "There are 5 in accordion_rot0.\n",
      "There are 5 in flask_rot1.\n",
      "There are 5 in scanner_rot0.\n",
      "There are 5 in jacket_rot0.\n",
      "There are 4 in scanner_rot1.\n",
      "There are 5 in flask_rot0.\n",
      "There are 5 in accordion_rot1.\n",
      "There are 4 in umbrella_rot0.\n",
      "There are 4 in towel_rot0.\n",
      "There are 4 in pitcher_rot1.\n",
      "There are 5 in nailpolish_rot1.\n",
      "There are 5 in tool_box_rot1.\n",
      "There are 5 in tennis_racket_rot1.\n",
      "There are 5 in measuring_spoons_rot0.\n",
      "There are 5 in packingtape_rot1.\n",
      "There are 5 in chapstick_rot0.\n",
      "There are 4 in briefcase_rot0.\n",
      "There are 5 in jug_rot0.\n",
      "There are 5 in chair_recliner_rot1.\n",
      "There are 5 in lotion_rot1.\n",
      "There are 5 in cocktail_umbrella_rot1.\n",
      "There are 5 in cocktail_umbrella_rot0.\n",
      "There are 5 in phone_antique_rot1.\n",
      "There are 5 in jug_rot1.\n",
      "There are 5 in briefcase_rot1.\n",
      "There are 5 in chapstick_rot1.\n",
      "There are 5 in measuring_spoons_rot1.\n",
      "There are 4 in pitcher_rot0.\n",
      "There are 5 in tennis_racket_rot0.\n",
      "There are 4 in fakeapple_rot0.\n",
      "There are 5 in packingtape_rot0.\n",
      "There are 5 in chair_recliner_rot0.\n",
      "There are 5 in phone_antique_rot0.\n",
      "There are 5 in fakeapple_rot1.\n",
      "There are 5 in box_hat_rot0.\n",
      "There are 5 in box_hat_rot1.\n",
      "There are 5 in holy_vase_rot0.\n",
      "There are 5 in jacket_rot1.\n",
      "There are 4 in clamp_rot0.\n",
      "There are 4 in clamp_rot1.\n",
      "There are 4 in umbrella_rot1.\n",
      "There are 5 in holy_vase_rot1.\n"
     ]
    }
   ],
   "source": [
    "for object_id in id_to_object:\n",
    "    id_to_object[object_id] = [fn for fn in id_to_object[object_id] if fn in all_images_with_annotations]\n",
    "\n",
    "\n",
    "for object_id in id_to_object:\n",
    "    print(f\"There are {len(id_to_object[object_id])} in {object_id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Combining Color Annotations with Object Categories\n",
    "\n",
    "Now that we have mappings between colors and images and between object categories and images, we can start to create our evaluation dataset.\n",
    "\n",
    "Each data point is framed as a question, a set of choices, and the correct answer(s).\n",
    "\n",
    "- When the question is a color text, the set of choices is a list of images. \n",
    "- When the question is an image, the set of choices is color terms. \n",
    "\n",
    "First, we generate the part where we give models a color text and ask it to choose between images of the same object kind but in different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['green'], ['blue'], ['blue'], ['red', 'pink']]\n",
      "[['green'], ['red', 'brown'], ['purple'], ['purple'], ['yellow', 'green']]\n",
      "[['yellow'], ['green'], ['red', 'pink'], ['blue'], ['pink']]\n",
      "[['blue'], ['yellow'], ['green'], ['blue']]\n",
      "[['yellow', 'orange'], ['blue', 'green'], ['pink'], ['purple'], ['green']]\n",
      "[['purple'], ['pink'], ['green'], ['orange'], ['yellow', 'green']]\n",
      "[['pink'], ['red', 'brown'], ['blue'], ['green'], ['blue']]\n",
      "[['red', 'pink'], ['green'], ['green'], ['purple'], ['blue']]\n",
      "[['pink'], ['green'], ['orange'], ['yellow', 'green'], ['blue']]\n",
      "[['blue'], ['purple'], ['green'], ['red', 'brown'], ['green']]\n",
      "[['red'], ['purple'], ['yellow', 'green'], ['blue'], ['green']]\n",
      "[['purple'], ['green'], ['green'], ['blue'], ['red', 'brown']]\n",
      "[['orange'], ['pink'], ['yellow', 'green'], ['blue', 'purple'], ['green']]\n",
      "[['blue'], ['red', 'pink'], ['green'], ['green'], ['purple']]\n",
      "[['brown'], ['blue'], ['blue'], ['pink'], ['green']]\n",
      "[['pink'], ['purple'], ['green'], ['orange'], ['yellow', 'green']]\n",
      "[['green'], ['yellow', 'green'], ['blue'], ['red', 'pink'], ['purple']]\n",
      "[['blue', 'green'], ['purple'], ['pink'], ['green'], ['yellow', 'orange']]\n",
      "[['green'], ['pink'], ['pink'], ['yellow'], ['blue']]\n",
      "[['yellow'], ['green'], ['blue'], ['blue']]\n",
      "[['red', 'pink'], ['green'], ['blue'], ['blue']]\n",
      "[['purple'], ['purple'], ['brown'], ['green'], ['green']]\n",
      "[['blue'], ['blue'], ['red', 'pink'], ['yellow', 'green'], ['green']]\n",
      "[['green'], ['blue'], ['yellow', 'green'], ['brown', 'orange'], ['purple']]\n",
      "[['green'], ['purple'], ['red', 'brown'], ['blue'], ['green']]\n",
      "[['red'], ['blue'], ['purple'], ['green'], ['yellow', 'green']]\n",
      "[['purple'], ['blue'], ['yellow', 'green'], ['pink'], ['green']]\n",
      "[['blue', 'green'], ['purple'], ['green'], ['green'], ['red', 'purple']]\n",
      "[['green'], ['green'], ['red', 'brown'], ['purple'], ['blue']]\n",
      "[['blue'], ['brown', 'orange'], ['yellow', 'green'], ['purple'], ['green']]\n",
      "[['green'], ['red', 'pink'], ['yellow', 'green'], ['purple'], ['blue']]\n",
      "[['purple'], ['green'], ['green'], ['purple'], ['brown']]\n",
      "[['red'], ['yellow', 'green'], ['blue'], ['blue']]\n",
      "[['blue'], ['blue'], ['red', 'pink'], ['green'], ['yellow', 'green']]\n",
      "[['red'], ['yellow', 'green'], ['blue'], ['blue', 'green']]\n",
      "[['red'], ['yellow', 'green'], ['blue'], ['blue']]\n",
      "[['green'], ['blue'], ['green'], ['purple'], ['brown']]\n",
      "[['purple'], ['pink'], ['blue'], ['yellow', 'green'], ['green']]\n",
      "[['red', 'brown'], ['yellow', 'green'], ['purple'], ['green'], ['purple']]\n",
      "[['purple'], ['red', 'brown'], ['blue'], ['green'], ['green']]\n",
      "[['yellow', 'green'], ['orange'], ['purple'], ['green'], ['pink']]\n",
      "[['blue'], ['green'], ['brown'], ['purple'], ['green']]\n",
      "[['blue'], ['green'], ['yellow', 'orange'], ['yellow', 'green']]\n",
      "[['green'], ['green'], ['blue'], ['brown']]\n",
      "[['purple'], ['green'], ['green'], ['blue']]\n",
      "[['brown', 'orange'], ['red', 'pink'], ['green'], ['blue'], ['green']]\n",
      "[['green'], ['yellow', 'green'], ['blue'], ['pink'], ['blue', 'purple']]\n",
      "[['green'], ['brown'], ['blue'], ['green']]\n",
      "[['pink'], ['purple'], ['green'], ['green'], ['orange']]\n",
      "[['purple'], ['pink'], ['green'], ['orange'], ['green']]\n",
      "[['green'], ['brown'], ['pink'], ['green'], ['blue']]\n",
      "[['purple'], ['blue'], ['green'], ['green']]\n",
      "[['brown', 'orange'], ['blue'], ['red', 'pink'], ['green'], ['green']]\n",
      "[['brown'], ['blue'], ['blue'], ['green']]\n",
      "[['green'], ['pink'], ['blue', 'purple'], ['yellow', 'green'], ['blue']]\n",
      "[['brown'], ['blue'], ['blue'], ['green'], ['pink']]\n",
      "[['green'], ['purple'], ['blue'], ['brown'], ['green']]\n",
      "[['blue'], ['green'], ['purple'], ['green'], ['brown']]\n",
      "[['red', 'pink'], ['blue', 'purple'], ['green'], ['purple'], ['yellow']]\n",
      "[['yellow', 'green'], ['green'], ['orange'], ['purple'], ['pink']]\n",
      "[['blue'], ['green'], ['yellow', 'orange'], ['yellow', 'green']]\n"
     ]
    }
   ],
   "source": [
    "# check images that are annotated with multiple colors have unique color annotations in the object class. In other words\n",
    "# we do not want two images in the same class that can both be classified as red\n",
    "for obj_id in id_to_object:\n",
    "    annotations = [image_to_colors_dict[fn] for fn in id_to_object[obj_id]]\n",
    "    collapsed_annotations = sum(annotations, [])\n",
    "    try:\n",
    "        assert len(collapsed_annotations) == len(set(collapsed_annotations))\n",
    "    except:\n",
    "        AssertionError(print(annotations))\n",
    "        # AssertionError(print(list(zip(annotations, id_to_object[obj_id]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This part of the dataset contains 454 items.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "data = []\n",
    "for obj_id in id_to_object:\n",
    "    annotations = [image_to_colors_dict[fn] for fn in id_to_object[obj_id]]\n",
    "    image_and_gold_annotation_pairs = [(fn, image_to_colors_dict[fn]) for fn in id_to_object[obj_id]]\n",
    "\n",
    "    one_to_one = True\n",
    "    no_overlap = True\n",
    "\n",
    "    if len(set(sum(annotations, []))) != len(sum(annotations, [])): # if there are overlap of colors:\n",
    "        no_overlap = False\n",
    "    \n",
    "    # colors that appear more than once\n",
    "    counts = Counter(sum(annotations, []))\n",
    "    duplicates = [item for item, count in counts.items() if count > 1]\n",
    "    \n",
    "    for a in annotations:\n",
    "        if len(a) != 1:\n",
    "            one_to_one = False\n",
    "            break\n",
    "    \n",
    "    if one_to_one and no_overlap:\n",
    "        for fn, g in image_and_gold_annotation_pairs:\n",
    "            d = {}\n",
    "            \n",
    "            d[\"question\"] = g[0]\n",
    "            d[\"choices\"] = id_to_object[obj_id] # all files under this obj_id can be choices\n",
    "            d[\"correct\"] = [fn]\n",
    "            d[\"type\"] = 0 # given color term choose image\n",
    "            data.append(d)\n",
    "\n",
    "    elif not one_to_one and no_overlap: # multiple annotations for one image but there is no overlap of colors between images:\n",
    "        for fn, gs in image_and_gold_annotation_pairs:\n",
    "            for g in gs:\n",
    "                d = {}\n",
    "\n",
    "                d[\"question\"] = g\n",
    "                d[\"choices\"] = id_to_object[obj_id]\n",
    "                d[\"correct\"] = [fn]\n",
    "                d[\"type\"] = 0\n",
    "                data.append(d)\n",
    "\n",
    "    elif not no_overlap: # if there is overlap\n",
    "        assert len(duplicates) >= 1\n",
    "        for color in counts.keys():\n",
    "            d = {}\n",
    "            d[\"question\"] = color\n",
    "            d[\"choices\"] = id_to_object[obj_id]\n",
    "            d[\"correct\"] = [fn for fn in d[\"choices\"] if color in image_to_colors_dict[fn]] # if current question color exists in the annotations list\n",
    "            d[\"type\"] = 0\n",
    "            data.append(d)           \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "print(f\"This part of the dataset contains {len(data)} items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we generate the part where we give models an image and a set of color terms to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset size is 454.\n",
      "The dataset size is 901.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset size is {len(data)}.\")\n",
    "for image_fn in all_images_with_annotations:\n",
    "    d = {}\n",
    "    d[\"question\"] = image_fn\n",
    "    d[\"choices\"] = COLORS_TEST\n",
    "    d[\"correct\"] = image_to_colors_dict[image_fn]\n",
    "    d[\"type\"] = 1\n",
    "    data.append(d)\n",
    "\n",
    "print(f\"The dataset size is {len(data)}.\")\n",
    "\n",
    "import pandas as pd\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df.to_csv(\"color_evaluation_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Evaluation\n",
    "\n",
    "We now run the CVCL model on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mirandazhu/anaconda3/envs/schuster/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:244: UserWarning: Attribute 'vision_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['vision_encoder'])`.\n",
      "  rank_zero_warn(\n",
      "/Users/mirandazhu/anaconda3/envs/schuster/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:244: UserWarning: Attribute 'text_encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['text_encoder'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiModalLitModel(\n",
       "  (vision_encoder): VisionEncoder(\n",
       "    (model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (text_encoder): TextEncoder(\n",
       "    (embedding): Embedding(2350, 512, padding_idx=0)\n",
       "    (lockdrop): LockedDropout()\n",
       "    (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (model): MultiModalModel(\n",
       "    (image_embed): VisionEncoder(\n",
       "      (model): ResNet(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (text_embed): TextEncoder(\n",
       "      (embedding): Embedding(2350, 512, padding_idx=0)\n",
       "      (lockdrop): LockedDropout()\n",
       "      (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (language_model): LanguageModel(\n",
       "    (text_encoder): TextEncoder(\n",
       "      (embedding): Embedding(2350, 512, padding_idx=0)\n",
       "      (lockdrop): LockedDropout()\n",
       "      (output_dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (output_layer): Linear(in_features=512, out_features=2350, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from multimodal.multimodal_lit import MultiModalLitModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Loading model...\")\n",
    "cvcl, preprocess = MultiModalLitModel.load_model(model_name=\"cvcl\")\n",
    "cvcl = cvcl.to(device)\n",
    "cvcl.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# encoding images\n",
    "normalizer = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalize each channel\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "            transforms.Resize((224, 224),\n",
    "                              interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            normalizer,\n",
    "        ])\n",
    "vocab_dict = cvcl.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/901 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0316,  0.0410,  0.0112, -0.0588,  0.0039,  0.0318, -0.0039, -0.0107,\n",
      "          0.0598, -0.0294, -0.0438,  0.0216, -0.0101,  0.0280, -0.0767,  0.0260,\n",
      "          0.0690,  0.0104, -0.0658,  0.0317, -0.0033, -0.0415, -0.0267,  0.0526,\n",
      "          0.0485,  0.0012, -0.0343,  0.0389, -0.0348, -0.1257, -0.0290,  0.0008,\n",
      "          0.0162,  0.0455,  0.0727, -0.0179, -0.0099, -0.0163, -0.0137,  0.0235,\n",
      "         -0.0428,  0.0582,  0.0170, -0.0556,  0.0244, -0.0072,  0.0048,  0.0403,\n",
      "          0.0105, -0.0182,  0.0300,  0.0090,  0.0764,  0.0659, -0.0369, -0.0302,\n",
      "          0.0173, -0.0602,  0.0424, -0.0393,  0.0624, -0.0501,  0.0007,  0.0044,\n",
      "         -0.0396, -0.0363,  0.0197, -0.0182,  0.0401,  0.0698,  0.0420,  0.0161,\n",
      "         -0.0334, -0.0232, -0.0370, -0.0184, -0.1032,  0.0220,  0.0719, -0.0394,\n",
      "         -0.0007,  0.0101, -0.0392, -0.0066, -0.0361,  0.0333, -0.0599,  0.0566,\n",
      "          0.0803, -0.0397, -0.0097, -0.0538,  0.0103,  0.0074,  0.0444,  0.0502,\n",
      "         -0.0770, -0.0439,  0.0262,  0.0038, -0.0762, -0.0020,  0.0653,  0.0076,\n",
      "          0.0032, -0.0131, -0.0302, -0.0371, -0.0617, -0.0417,  0.0135,  0.0460,\n",
      "         -0.0145, -0.0125, -0.0382, -0.0004, -0.0852, -0.0900,  0.0948, -0.0259,\n",
      "         -0.0178, -0.0026, -0.0487,  0.0015, -0.0087,  0.0625, -0.0160, -0.0277,\n",
      "         -0.0407,  0.0323, -0.0097,  0.0128, -0.0437, -0.0744,  0.0245, -0.0216,\n",
      "          0.0393,  0.0687, -0.0309, -0.0373, -0.0210, -0.0661, -0.0332, -0.0713,\n",
      "         -0.0784,  0.0047,  0.0018, -0.0284,  0.0147,  0.0117,  0.0145,  0.0268,\n",
      "          0.0641, -0.0294, -0.0401,  0.0328,  0.0576, -0.0783, -0.0152,  0.0496,\n",
      "         -0.0716,  0.0337, -0.0861,  0.0074,  0.0547, -0.0100,  0.0010,  0.0200,\n",
      "         -0.0002, -0.0518, -0.0398, -0.0140, -0.0097,  0.0713,  0.0312,  0.0684,\n",
      "          0.0527, -0.1120, -0.0059, -0.1100,  0.0206,  0.0061,  0.0102,  0.0259,\n",
      "         -0.0772, -0.0187,  0.0361, -0.0160, -0.0068,  0.1089,  0.0133, -0.0807,\n",
      "          0.0138, -0.0159,  0.0141, -0.0362, -0.0318, -0.0227,  0.0029,  0.0093,\n",
      "          0.0130,  0.0406, -0.0058, -0.0059,  0.0541,  0.0709,  0.0332,  0.0315,\n",
      "          0.0037, -0.0291, -0.0022, -0.0345,  0.0261, -0.0690, -0.1098, -0.0436,\n",
      "         -0.0277, -0.0074,  0.0653,  0.0154, -0.0022,  0.0124, -0.0050, -0.0095,\n",
      "         -0.0298, -0.0282,  0.0109, -0.0132,  0.0329, -0.0648,  0.0229,  0.0225,\n",
      "          0.0404,  0.0141,  0.0091,  0.0400, -0.0271, -0.0108,  0.0529, -0.0616,\n",
      "         -0.0022, -0.0231,  0.0655,  0.0695,  0.0860, -0.0126, -0.0206,  0.0227,\n",
      "          0.0105,  0.0500,  0.0277,  0.0477,  0.0431, -0.0107, -0.0038,  0.0023,\n",
      "          0.0096,  0.0009, -0.0002, -0.0292, -0.0096, -0.0453,  0.0309, -0.0292,\n",
      "          0.0178, -0.0012,  0.0142, -0.0080,  0.0674,  0.0313, -0.0949, -0.1052,\n",
      "         -0.0286,  0.0192,  0.0290,  0.0179,  0.0487, -0.0318,  0.0272,  0.0435,\n",
      "         -0.0353,  0.1266, -0.0061,  0.0535, -0.0124,  0.0174, -0.0968, -0.0191,\n",
      "         -0.0495,  0.1129, -0.0455, -0.0002, -0.0207,  0.0066, -0.0596, -0.0269,\n",
      "         -0.0265, -0.0347, -0.0222, -0.0023,  0.1288,  0.0148, -0.0328, -0.0503,\n",
      "         -0.0189,  0.0206, -0.0346,  0.0794, -0.1011,  0.0167,  0.0222, -0.0409,\n",
      "          0.0120, -0.0117, -0.0624,  0.0074, -0.0048,  0.0054,  0.0427, -0.0168,\n",
      "         -0.0476, -0.0766, -0.0682, -0.0406, -0.0598,  0.0357, -0.0433, -0.0039,\n",
      "          0.0261,  0.0358, -0.0101,  0.0077, -0.0040,  0.0028, -0.0031,  0.0483,\n",
      "          0.0459, -0.0154, -0.0219, -0.0625, -0.0496, -0.0097,  0.0182, -0.0306,\n",
      "         -0.0117,  0.0098, -0.0289, -0.0958,  0.0385, -0.0007, -0.0393, -0.0245,\n",
      "         -0.0111,  0.0044,  0.0724, -0.0249,  0.0416, -0.0452,  0.0399, -0.0149,\n",
      "         -0.0492,  0.0585, -0.0752,  0.0863,  0.1039, -0.0617, -0.0084,  0.0759,\n",
      "         -0.0526,  0.0437,  0.1087, -0.0781, -0.0216, -0.0148,  0.0412, -0.0250,\n",
      "          0.0012, -0.0109, -0.0574, -0.0109,  0.0463,  0.0485,  0.0289,  0.0110,\n",
      "          0.0198,  0.0134,  0.0595, -0.0510, -0.0129, -0.0800, -0.0852, -0.0706,\n",
      "          0.0371, -0.0094,  0.0416, -0.0687, -0.0184, -0.0260,  0.0044,  0.0004,\n",
      "          0.1031,  0.0169,  0.0242,  0.0216,  0.0398,  0.0295,  0.0375, -0.0155,\n",
      "          0.0282, -0.0252,  0.0233,  0.0371,  0.0169, -0.0140, -0.0039,  0.0055,\n",
      "          0.0124,  0.1344, -0.0495, -0.0529, -0.0208,  0.0287, -0.0012,  0.0349,\n",
      "         -0.0043,  0.0143, -0.0689, -0.0081,  0.0034, -0.0838, -0.0006,  0.0134,\n",
      "         -0.0195, -0.0679, -0.0119, -0.0279,  0.0353, -0.0349, -0.1116, -0.0042,\n",
      "         -0.0206, -0.0235, -0.0436,  0.0421,  0.0167, -0.0169,  0.0416, -0.0332,\n",
      "         -0.0995, -0.0406, -0.0070, -0.0363, -0.0042,  0.0138, -0.0033,  0.0649,\n",
      "          0.0243, -0.0342, -0.0288,  0.0549,  0.0119,  0.0337,  0.0188, -0.0633,\n",
      "         -0.0471,  0.0077, -0.1216,  0.0357,  0.0761,  0.0463, -0.0755,  0.0438,\n",
      "          0.0493, -0.0044, -0.0169, -0.0082,  0.0741,  0.1015, -0.0701,  0.0632,\n",
      "         -0.0097,  0.0523,  0.0471, -0.0626,  0.0576,  0.0423,  0.0343,  0.0041,\n",
      "          0.0451, -0.0539, -0.0308,  0.0468,  0.0502, -0.0563,  0.0295,  0.0484,\n",
      "         -0.0010, -0.0398,  0.0201, -0.0242,  0.0011, -0.0026, -0.0243, -0.0133,\n",
      "          0.0542, -0.0586,  0.0264,  0.0192, -0.0174,  0.0384,  0.0003, -0.0288]],\n",
      "       grad_fn=<DivBackward0>) torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "for d in tqdm(data):\n",
    "    scores = [[] for i in d[\"choices\"]]\n",
    "\n",
    "    if d[\"type\"] == 0: # one text, multiple images\n",
    "        text = torch.tensor([vocab_dict[d[\"question\"]]]).unsqueeze(0).to(device)\n",
    "        text_len = torch.tensor([len(text)], dtype=torch.long).to(device)\n",
    "        text_features, _ = cvcl.model.encode_text(text, text_len) # size = 1 by 512\n",
    "\n",
    "        for j, fn in enumerate(d[\"choices\"]):\n",
    "            I = preprocess(Image.open(f\"konkle_objects_colored/{fn}\").convert('RGB')).unsqueeze(0).to(device)\n",
    "            image_features, _ = cvcl.model.encode_image(I)\n",
    "            print(image_features, image_features.size())\n",
    "            break\n",
    "            distance_score = F.pairwise_distance(image_features, text_features, p=2).item() # the smaller the closer\n",
    "            scores[j] = distance_score\n",
    "\n",
    "\n",
    "    elif d[\"type\"] == 1: # one image, multiple texts\n",
    "        I = preprocess(Image.open(f\"konkle_objects_colored/{d['question']}\").convert('RGB')).unsqueeze(0).to(device)\n",
    "        image_features, _ = cvcl.model.encode_image(I)\n",
    "\n",
    "        for j, color_term in enumerate(d[\"choices\"]):\n",
    "            text = torch.tensor([vocab_dict[color_term]]).unsqueeze(0).to(device)\n",
    "            text_len = torch.tensor([len(text)], dtype=torch.long).to(device)\n",
    "            text_features, _ = cvcl.model.encode_text(text, text_len) # size = 1 by 512\n",
    "            distance_score = F.pairwise_distance(image_features, text_features, p=2).item() # the smaller the closer\n",
    "            scores[j] = distance_score\n",
    "    break\n",
    "\n",
    "    # if len(d[\"correct\"]) == 1:\n",
    "    #     model_response_idx = np.argmin(scores)\n",
    "    #     if model_response_idx == d[\"choices\"].index(d[\"correct\"][0]):\n",
    "    #         d[\"accuracy\"] = 1\n",
    "    #     else:\n",
    "    #         d[\"accuracy\"] = 0\n",
    "    # else:\n",
    "    #     correct_choices_index = [d[\"choices\"].index(content) for content in d[\"correct\"]]\n",
    "    #     average_distance_for_correct_choices = sum(scores[i] for i in correct_choices_index) / len(correct_choices_index)\n",
    "    #     wrong_choices_index = [d[\"choices\"].index(content) for content in d[\"choices\"] if content not in d[\"correct\"]]\n",
    "    #     assert len(set(correct_choices_index+wrong_choices_index)) == len(correct_choices_index) + len(wrong_choices_index) # assert disjoint\n",
    "    #     average_distance_for_incorrect_choices = sum(scores[i] for i in wrong_choices_index) / len(wrong_choices_index)\n",
    "    #     if average_distance_for_correct_choices < average_distance_for_incorrect_choices:\n",
    "    #         d[\"accuracy\"] = 1\n",
    "    #     else:\n",
    "    #         d[\"accuracy\"] = 0\n",
    "    model_response_idx = np.argmin(scores)\n",
    "    d[\"model_response\"] = model_response_idx\n",
    "    # random_response_idx = random.choice(list(range(len(d[\"choices\"]))))\n",
    "    # d[\"random_response\"] = random_response_idx\n",
    "    baseline = len(d[\"correct\"])/len(d[\"choices\"])\n",
    "    d[\"accuracy_baseline\"] = baseline\n",
    "\n",
    "    correct_indices = []\n",
    "    for correct_ans in d[\"correct\"]:\n",
    "        correct_indices.append(d[\"choices\"].index(correct_ans))\n",
    "    if model_response_idx in correct_indices:\n",
    "        d[\"accuracy\"] = 1\n",
    "    else:\n",
    "        d[\"accuracy\"] = 0\n",
    "    # if random_response_idx in correct_indices:\n",
    "    #     d[\"accuracy_baseline\"] = 1\n",
    "    # else:\n",
    "    #     d[\"accuracy_baseline\"] = 0    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_accuracy_df = pd.DataFrame(data)\n",
    "data_accuracy_df.to_csv(\"color_evaluation_dataset_with_accuracy_updated_measure_and_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Visualization\n",
    "We now visualize the accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'choices', 'correct', 'type', 'model_response',\n",
       "       'random_response', 'accuracy', 'accuracy_baseline'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_accuracy_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy is: 0.1709211986681465\n",
      "Overall accuracy for type 0 questions is: 0.2621145374449339\n",
      "Overall accuracy for type 1 questions is: 0.07829977628635347\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Overall accuracy is: {sum(data_accuracy_df['accuracy'])/len(data_accuracy_df['accuracy'])}\")\n",
    "\n",
    "type0_df = data_accuracy_df[data_accuracy_df['type'] == 0]\n",
    "type1_df = data_accuracy_df[data_accuracy_df['type'] == 1]\n",
    "print(f\"Overall accuracy for type 0 questions is: {sum(type0_df['accuracy'])/len(type0_df['accuracy'])}\")\n",
    "print(f\"Overall accuracy for type 1 questions is: {sum(type1_df['accuracy'])/len(type1_df['accuracy'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at type 0 questions first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped_data = type0_df.groupby('question')[['accuracy', 'accuracy_baseline']].mean().reset_index()\n",
    "counts = type0_df[\"question\"].value_counts().reindex(grouped_data[\"question\"]).values\n",
    "\n",
    "###### PLOT WITH BASELINE #####\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(grouped_data['question']))\n",
    "\n",
    "# Create bar plots\n",
    "fig, ax = plt.subplots()\n",
    "bar1 = ax.bar(index, grouped_data['accuracy_baseline'], bar_width, label='Baseline Accuracy', color='lightblue')\n",
    "bar2 = ax.bar(index + bar_width, grouped_data['accuracy'], bar_width, label='Model Accuracy', color='coral')\n",
    "\n",
    "for bar, count in zip(bar1, counts):\n",
    "    plt.text(bar.get_x() + bar.get_width() , bar.get_height(), f'N={count}', \n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Color')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Baseline vs Model Accuracy by Color')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(grouped_data['question'])\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "###### OLD PLOT #######\n",
    "# plt.figure(figsize=(8, 4))\n",
    "\n",
    "# bars = plt.bar(grouped_data[\"question\"], grouped_data['accuracy'])\n",
    "\n",
    "# # Add labels for the number of items on top of each bar\n",
    "# for bar, count in zip(bars, counts):\n",
    "#     plt.text(bar.get_x() + bar.get_width() , bar.get_height(), f'N={count}', \n",
    "#                 ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel(\"Color\")\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title(f'Accuracy by color')\n",
    "# plt.xticks(rotation=45)  # Rotate labels if needed\n",
    "\n",
    "# # Display the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us look at type 1 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p5/4f2jvjd16dzcqk4v24z60cpm0000gn/T/ipykernel_57113/1625770199.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  type1_df[\"kind\"] = type1_df[\"question\"].map(object_to_id)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>correct</th>\n",
       "      <th>type</th>\n",
       "      <th>model_response</th>\n",
       "      <th>random_response</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>packingtape_rot_s_1.jpg</td>\n",
       "      <td>[blue, red, yellow, green, brown, orange, pink...</td>\n",
       "      <td>[green]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>packingtape_rot1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>chapstick_rot_s_5.jpg</td>\n",
       "      <td>[blue, red, yellow, green, brown, orange, pink...</td>\n",
       "      <td>[yellow]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>chapstick_rot1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>jug_rot_s_8.jpg</td>\n",
       "      <td>[blue, red, yellow, green, brown, orange, pink...</td>\n",
       "      <td>[orange]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>jug_rot0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>fuel_tank_rot_s_8.jpg</td>\n",
       "      <td>[blue, red, yellow, green, brown, orange, pink...</td>\n",
       "      <td>[blue]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>fuel_tank_rot0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>gloves_rot_s_9.jpg</td>\n",
       "      <td>[blue, red, yellow, green, brown, orange, pink...</td>\n",
       "      <td>[brown]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>gloves_rot1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    question  \\\n",
       "454  packingtape_rot_s_1.jpg   \n",
       "455    chapstick_rot_s_5.jpg   \n",
       "456          jug_rot_s_8.jpg   \n",
       "457    fuel_tank_rot_s_8.jpg   \n",
       "458       gloves_rot_s_9.jpg   \n",
       "\n",
       "                                               choices   correct  type  \\\n",
       "454  [blue, red, yellow, green, brown, orange, pink...   [green]     1   \n",
       "455  [blue, red, yellow, green, brown, orange, pink...  [yellow]     1   \n",
       "456  [blue, red, yellow, green, brown, orange, pink...  [orange]     1   \n",
       "457  [blue, red, yellow, green, brown, orange, pink...    [blue]     1   \n",
       "458  [blue, red, yellow, green, brown, orange, pink...   [brown]     1   \n",
       "\n",
       "     model_response  random_response  accuracy  accuracy_baseline  \\\n",
       "454               5                1         0              0.125   \n",
       "455               5                1         0              0.125   \n",
       "456               1                6         0              0.125   \n",
       "457               5                0         0              0.125   \n",
       "458               5                6         0              0.125   \n",
       "\n",
       "                 kind  \n",
       "454  packingtape_rot1  \n",
       "455    chapstick_rot1  \n",
       "456          jug_rot0  \n",
       "457    fuel_tank_rot0  \n",
       "458       gloves_rot1  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type1_df[\"kind\"] = type1_df[\"question\"].map(object_to_id)\n",
    "type1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <th>accuracy_higher_than_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>umbrella_rot1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>jug_rot1</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>watch_rot1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>towel_rot0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>fakeapple_rot0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>packingtape_rot0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>packingtape_rot1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chapstick_rot0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>pail_rot1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>lotion_rot1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                kind  accuracy  accuracy_baseline  \\\n",
       "86     umbrella_rot1      0.50             0.1875   \n",
       "42          jug_rot1      0.40             0.1250   \n",
       "92        watch_rot1      0.25             0.1875   \n",
       "81        towel_rot0      0.25             0.1250   \n",
       "23    fakeapple_rot0      0.25             0.1250   \n",
       "..               ...       ...                ...   \n",
       "55  packingtape_rot0      0.00             0.1750   \n",
       "56  packingtape_rot1      0.00             0.1750   \n",
       "11    chapstick_rot0      0.00             0.1500   \n",
       "58         pail_rot1      0.00             0.1500   \n",
       "46       lotion_rot1      0.00             0.1500   \n",
       "\n",
       "    accuracy_higher_than_baseline  \n",
       "86                              1  \n",
       "42                              1  \n",
       "92                              1  \n",
       "81                              1  \n",
       "23                              1  \n",
       "..                            ...  \n",
       "55                              0  \n",
       "56                              0  \n",
       "11                              0  \n",
       "58                              0  \n",
       "46                              0  \n",
       "\n",
       "[93 rows x 4 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data = type1_df.groupby(\"kind\")[['accuracy', 'accuracy_baseline']].mean().reset_index()\n",
    "# grouped_data = grouped_data[grouped_data['accuracy'] > 0] # only look at those ones with non zero accuracy\n",
    "sorted_df = grouped_data.sort_values(by='accuracy',ascending=False)\n",
    "sorted_df[\"accuracy_higher_than_baseline\"] = (sorted_df[\"accuracy\"] > sorted_df[\"accuracy_baseline\"]).astype(int)\n",
    "sorted_df\n",
    "# print(f\"Percentage of kinds that surpass the baseline: {sorted_df['accuracy_higher_than_baseline'].mean()}\")\n",
    "# sorted_df.to_csv(\"color_evaluation_accuracy_given_kind_pick_color.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of kinds that surpass the baseline: 0.3548387096774194\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of kinds that surpass the baseline: {sorted_df['accuracy_higher_than_baseline'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Confusion Matrix\n",
    "[TODO]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schuster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
